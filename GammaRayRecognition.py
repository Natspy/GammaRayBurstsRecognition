# -*- coding: utf-8 -*-
"""NK_Praca_domowa_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14cqqMmqx2R-J-wc17aEFY_iTcGCaHu4Z

# Rozpoznawanie obrazu na potrzeby eksperymentu naukowego

Pi of the Sky (https://www.pi.fuw.edu.pl/jest) jest eksperymentem astrofizycznym, którego głównym celem jest poszukiwanie rozbłysków gamma (GRB) (https://pl.wikipedia.org/wiki/Rozbłysk_gamma). W tym celu zautomatyzowane teleskopy w Chile i Hiszpanii fotografują niebo w poszukiwaniu interesujących zdarzeń. Klasyczne algorytmy wykrywania rozbłysków gamma działają w następujący sposób: wybrany obszar nieba jest stale fotografowany w pewnych odstępach czasu, jeżeli skanowany obszar zmieni się w jakiś sposób, może to oznaczać, iż pojawiło się nowe źródło promieniowania, dlatego kilka(naście) klatek (zdjęć) przed i po wystąpieniu zjawiska jest zachowywanych do późniejszej analizy. Naukowcy analizują sekwencję zdjęć aby stwierdzić, czy faktycznie zaobserwowano rozbłysk gamma. Niestety, wiele spośród zebranych danych to fałszywe alarmy, wywołane np. przez chmury poruszające się na niebie. Celem niniejszego ćwiczenia jest stworzenie algorytmu uczenia maszynowego opartego o konwolucyjne sieci neuronowe, który mógłby usprawnić analizę poprzez odsiewanie niepoprawnych danych, oszczędzając pracy naukowcom.

W zadaniu chcemy stworzyć tzw. "proof of concept", czyli rozwiązanie dalekie od ostatecznego, ale pokazujące, że problem może potencjalnie zostać rozwiązany z użyciem zaproponowanej metody. Ograniczymy się do analizy pojedynczych obrazów a nie całych sekwencji. Chcemy dokonać klasyfikacji obrazów należących do trzech klas:

0) zdjęcia potencjalnie zawierające rozbłyski gamma 

1) fałszywe alarmy przedstawiające niebo z chmurami

2) fałszywe alarmy zawierające artefakty spowodowane wadliwą pracą aparatury badawczej (poziome/pionowe linie)

## Polecenia

#### Uwaga ogólna: Wszystkie wykresy i obrazki w notatniku mają być estetyczne, zawierać podpisy osi, tytuły, legendy itp. Wypisując jakieś wartości należy napisać również czym one są. Przed wysłaniem rozwiązania należy usunąć wszystkie niepotrzebne komentarze i komórki. Mile widziane są opisy/komentarze wyjaśniające co w danej komórce próbujecie zrobić.

1. Wczytanie i wstępna obróbka danych
     * Proszę pobrać archiwum "data.zip":
     https://github.com/Rav2/uczenie-maszynowe-2021-22/raw/main/praca_domowa/data.zip
     * Archiwum należy rozpakować. Folder "data" zawiera trzy podfoldery odpowiadające trzem klasom: "0", "1" oraz "2", które zawierają obrazki w formacie JPG. Wszystkie obrazki mają identyczne wymiary. Jeśli chcecie pracować w Google Collab, to polecam przesłać obrazki na dysk Google i podłączyć ten dysk do notebooka (instrukcja niżej).
     * Proszę wczytać obrazki, np. korzystając z funkcji
     tensorflow.keras.preprocessing.image.load_img (patrz przykład poniżej) i stworzyć tensor cech X i wektor etykiet y.
     * Tensor cech powinnien mieć wymiar (3573, 100, 100, 1). 1 odpowiada pojedynczemu kanałowi (czarno-biały obraz). Jeżeli dane nie mają takiego kształtu to proszę im go nadać.
     * Proszę sprawdzić i wyświetlić liczebność klas.
     * Proszę sprawdzić i wyświetlić wymiary obrazka (w pikselach) i zapisać do zmiennych. Przydadzą się później.
     * Proszę wyświetlić po jednym obrazku z każdej klasy wraz z numerem klasy.
2. Preprocessing
     * Proszę przeskalować wartości pikseli tak, żeby były w przedziale [0,1].
     * Proszę podzielić dane na zbiory uczący (70%) i testowy (30%).
     * Proszę sprawdzić, czy rozkład klas w obu zbiorach jest zbliżony. Jeżeli nie jest, to proszę dokonać podziału danych tak, żeby był.
3. Uczenie sieci
    * Proszę zaproponować architekturę sieci opartą o warstwy CNN. Proszę wykorzystać również pooling oraz dropout i pamiętać o spłaszczeniu na końcu. Sieć ma przyjmować obrazki w oryginalnych rozmiarach. Proszę pamiętać o właściwej funkcji aktywacji w ostatniej warstwie.
    * Proszę wytrenować sieć wydzielając ze zbioru uczącego 15% na walidację.
    * Proszę narysować wykresy accuracy i funkcji kosztu w funkcji numeru epoki (iteracji) uczenia, zarówno dla zbioru uczącego jak i walidacyjnego.
4. Ewaluacja
    * Proszę dokonać predykcji na zbiorze testowym.
    * Proszę wypisać raport z klasyfikacji i macierz pomyłek. W przypadku otrzymania mniej niż 80% accuracy proszę porawić architekturę i parametry sieci.
    * Proszę policzyć procent poprawnie sklasyfikowanych obrazków dla każdej z klas i przedstawić na histogramie.
    * Proszę narysować wykres ROC i podać pole wykresu pod krzywą. 
5. Generacja pseudodanych
  * Proszę zapoznać się z dokumentacją klasy tensorflow.keras.preprocessing.image.ImageDataGenerator oraz przykładami użycia.
  * Proszę stworzyć obiekt typu ImageDataGenerator z parametrami pozwalającymi na generację pseudodanych poprzez użycie:
    a) przesunięcia o nie wiecej niż 20 pikseli
    b) odbicia względem osi OX lub OY
    c) zoom do 10%
  * Proszę przeznaczyć 15% zbioru treningowego na zbiór walidacyjny.
  * Korzystając z metody "flow" dla obiektu typu ImageDataGenerator proszę wytrenować sieć neuronową.
  * Proszę przeprowadzić ponowną ewaluację sieci wytrenowanej z generacją pseudodanych.
  *Proszę porównać wyniki z wcześniejszymi i napisać kilka zdań komentarza z wyjaśnieniem obecności lub braku różnic.

6. Dodatkowe (dla chętnych)
    * Znaleźć optymalne wartości hiperparametrów sieci w sposób automatyczny, wykorzystując jedną z dostępnych bibliotek lub implementując samemu, np. z użyciem zagnieżdżonych pętli for.
    * Dla znalezionych parametrów wykonać uczenie i ewaluację. Porównać z wcześniejszymi wynikami.

#### Pobranie danych i rozpakowanie
"""

# Pobieranie danych
#! wget https://github.com/Rav2/uczenie-maszynowe-2021-22/raw/main/praca_domowa/data.zip
#! unzip -q data.zip

""" #### Podpięcie dysku Google do notebooka (po tym wszystkie pliki na dysku będą dostępne, trzeba zatwierdzić w wyskakujących okienkach)"""

# Podłączanie dysku google
from google.colab import drive
drive.mount('/content/drive')

"""# Rozwiązanie - Natalia Karczewska 418376

## Wczytywanie i wstępna obróbka danych
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

import os
from tensorflow.keras.preprocessing.image import load_img

# Funkcja do wczytywania obrazów
def load_images(folder_name):
  files = os.listdir('/content/drive/MyDrive/uczenie_maszynowe_2021-22/data/' + folder_name)
  imgs = [] 
  for i in range(len(files)): 
    path = os.path.join('/content/drive/MyDrive/uczenie_maszynowe_2021-22/data/' + folder_name, files[i])
    img = load_img(path, color_mode='grayscale')
    img_arr = np.asarray(img)
    imgs.append(img_arr)
  return imgs

# Wczytuję obrazy
imgs1 = load_images("1")
imgs0 = load_images("0")
imgs2 = load_images("2")

# Wyświetlam po jednym obrazie z każdej klasy

plt.figure(figsize=(15,4))
plt.subplot(1,3,1)
plt.imshow(imgs0[0], cmap='gray')
plt.title("Potencjalny rozbłysk gamma - klasa 0")
plt.grid(False)

plt.subplot(1,3,2)
plt.imshow(imgs1[0], cmap='gray')
plt.title("Fałszywy alarm (chmury) - klasa 1")
plt.grid(False)

plt.subplot(1,3,3)
plt.imshow(imgs2[0], cmap='gray')
plt.title("Fałszywy alarm (artefakty aparaturowe) - klasa 2")
plt.grid(False)
plt.show()

# Tworzenie wartości do wpisania do wektora klas

def make_label(list_of_images, class_num):
  label = np.zeros(len(list_of_images))
  for i in range(len(list_of_images)):
    label[i] = class_num
  return label

label0 = make_label(imgs0, 0)
label1 = make_label(imgs1, 1)
label2 = make_label(imgs2, 2)

print("Liczebność klasy 0: ", len(label0))
print("Liczebność klasy 1: ", len(label1))
print("Liczebność klasy 2: ", len(label2))
print("Suma liczebności: ", len(label2) + len(label1) + len(label0))

# Zapis do zmiennych wymiarów obrazka w pikselach

width = imgs1[0].shape[0]
height = imgs1[0].shape[1]

print("Wymiary obrazka w pikselach - wysokość: ", height)
print("Wymiary obrazka w pikselach - szerokosć: ", width)

"""## Preprocessing"""

# Odpowiednie złączenie danych w celu wytworzenia macierzy cech (features) oraz wektora klas (labels)

features = np.concatenate((imgs0, imgs1))
features = np.concatenate((features, imgs2))

labels = np.concatenate((label0, label1))
labels = np.concatenate((labels, label2))

# Przeskalowanie wartości do zakresu od 0 do 1

maxValue = float(np.amax(features))
print("Maksymalna wartość w macierzy cech przed normalizacją:", maxValue)
features = features.astype('float32')/maxValue
maxValue = float(np.amax(features))
print("Maksymalna wartość w macierzy cech po normalizacji:", maxValue)

# Zmiana kształtu macierzy cech na (3573, 100, 100,1)

features = features.reshape(features.shape+(-1,))
print("-"*60)

print("kształt macierzy cech:", features.shape)
print("kształt wektora klas:", labels.shape)

# Podział danych na zbiór uczący (70%) i testowy (30%)

X_train, X_test, y_train, y_test1 = train_test_split(features, labels, test_size=0.3)

# Histogramy rozkładu klas dla zbioru treningowego i testowego
fig = plt.figure(figsize = (12,7))

plt.subplot(1,2,1)
labels, counts = np.unique(y_train, return_counts=True,)
plt.bar(labels, counts, align='center', color="lightskyblue", edgecolor='black', alpha=0.75)
plt.gca().set_xticks(labels)
plt.grid(True, linestyle='-.', color='grey')
plt.ylabel("Liczebność klasy")
plt.title("Rozkład klas - zbiór treningowy")

plt.subplot(1,2,2)
labels, counts = np.unique(y_test1, return_counts=True,)
plt.bar(labels, counts, align='center', color="pink", edgecolor='black', alpha=0.75)
plt.gca().set_xticks(labels)
plt.grid(True, linestyle='-.', color='grey')
plt.title("Rozkład klas - zbiór testowy")

plt.show()

"""#### Obserwacja:
Rozkład klas w zbiorze treningowym jest zbliżony do rozkładu klas w zbiorze testowym.
"""

# Stworzenie tensorów cech
X_train = tf.constant(X_train)
X_test = tf.constant(X_test)
print("Kształt tensora cech - zbiór treningowy: ", X_train.shape)
print("Kształt tensora cech - zbiór testowy: ", X_test.shape)
print("-"*60)

# Zmiana reprezentacji etykiet (one hot encoding)
print("Oryginalna reprezentacja wektora etykiet:", labels[0], "shape:", labels.shape)
depth = 3

y_train = tf.one_hot(y_train, depth)
y_test = tf.one_hot(y_test1, depth)

print("One hot encoding (zbiór treningowy): ", y_train[0], "shape:", y_train.shape)
print("One hot encoding (zbiór testowy): ", y_test[20], "shape:", y_test.shape)

"""## Tworzenie  architektury sieci konwolucyjnej"""

# Funkcja, która tworzy model o zdefiniowanej architekturze

def getModel(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, dropout_rate, inputShape, outputWidth):     
    inputs = tf.keras.Input(shape=inputShape)
    x = inputs
    for iHidden in range(nHiddenLayers):   
        x = tf.keras.layers.Conv2D(filters=nFilters, kernel_size=kernel_size, activation=tf.nn.relu)(x)
        x = tf.keras.layers.MaxPooling2D(pool_size=pool_size)(x)
        x = tf.keras.layers.Dropout(dropout_rate)(x)
    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(nNeurons, activation=tf.nn.relu)(x)
    outputs = tf.keras.layers.Dense(outputWidth, activation=tf.nn.softmax)(x)
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Wybór parametrów   

inputShape = (width, height, 1)
outputWidth = 3 # liczba klas
nFilters = 32
kernel_size = 3
pool_size = (2,2)
nNeurons = 128 
nHiddenLayers = 1 
dropout_rate = 0.2

model = getModel(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, dropout_rate, inputShape, outputWidth)

# Podsumowanie modelu 

tf.keras.utils.plot_model(model, 'ML_model.png', show_shapes=True)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Trenowanie modelu
#  
# epochs = 10
# batch_size = 128
# 
# model_fit = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.15)

# Funkcja służąca do wyrysowania wykresu dokładności (accuracy) i funkcji kosztu w funkcji numeru epoki
def plotTrainingHistory(model):
    plt.figure(figsize = (12,7))

    plt.subplot(1,2,1)
    history = model.history
    plt.plot(history['accuracy'])
    plt.plot(history['val_accuracy'])
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.title('Wykres dokładności w funkcji numeru epoki')
    plt.grid(True, linestyle='-.', color='grey')
    plt.legend(['train', 'validation'], loc='upper left')

    plt.subplot(1,2,2)
    plt.plot(history['loss'])
    plt.plot(history['val_loss'])
    plt.ylabel('loss function')
    plt.xlabel('epoch')
    plt.title('Wykres funkcji kosztu w funkcji numeru epoki')
    plt.grid(True, linestyle='-.', color='grey')
    plt.legend(['train', 'validation'], loc='upper left')
    
plotTrainingHistory(model_fit)

"""#### Obserwacja:
Zgodnie z oczekiwaniami, wraz z kolejnymi epokami rośnie dokładność modelu, zarówno dla zbioru uczącego jak i walidacyjnego. Natomiast funkcja kosztu, maleje wraz ze wzrostem epoki - zatem parametry modelu są coraz lepiej dopasowane.

## Ewaluacja modelu
"""

# Funkcja wykonująca predykcję + raport klasyfikacyjny z miarami jakości 
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

def printScores(model, X, Y):
    Y_pred = np.argmax(model.predict(X), axis=1)
    print("-"*55)
    print("Classification report:")
    print(classification_report(Y,Y_pred))
    print("-"*55)
    print("Confusion matrix:")
    print(confusion_matrix(Y, Y_pred))
    print("-"*55)
    return confusion_matrix(Y, Y_pred)
    
conf_matrix = printScores(model, X_test, np.argmax(y_test, axis=1))

"""#### Obserwacja
Miary jakości modelu wyglądają bardzo dobrze - dokładność osiąga wartość około 97%. Większość obrazów niezależnie od klasy jest klasyfikowanych poprawnie z podobną skutecznością, jedynie obrazki należące do klas 0 i 1 są trochę częściej błędnie klasyfikowane, lecz w dalszym ciągu dosyć rzadko.
"""

# Obliczenie procenta poprawnie sklasyfikowanych obrazków dla każdej klasy
true0 = conf_matrix[0][0] / np.sum(conf_matrix[0])
true1 = conf_matrix[1][1] / np.sum(conf_matrix[1])
true2 = conf_matrix[2][2] / np.sum(conf_matrix[2])

print("Procent poprawnie sklasyfikowanych obrazków w klasie 0: {}%".format(round(true0*100,2)))
print("Procent poprawnie sklasyfikowanych obrazków w klasie 1: {}%".format(round(true1*100,2)))
print("Procent poprawnie sklasyfikowanych obrazków w klasie 2: {}%".format(round(true2*100,2)))

# Histogram procenta obrazków sklasyfikowanych poprawnie dla każdej z klas
fig = plt.figure(figsize = (8,6))

labels = np.unique(labels, return_counts=False)
plt.bar(labels, [true0, true1, true2], align='center', color=["plum", "thistle","pink"], edgecolor='black', alpha=0.75)
plt.gca().set_xticks(labels)
plt.grid(True, linestyle='-.', color='grey')
plt.ylabel("Procent")
plt.xlabel("klasa")
plt.ylim(0.8, 1.02)
plt.title("Procent poprawnie sklasyfikowanych obrazków dla każdej z klas")

plt.show()

# Wykres krzywej ROC oraz pole pod krzywą (AUC)
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

y_pred = np.argmax(model.predict(X_test), axis=1)

# Ponieważ klasyfikacja nie jest binarna, należy "zbinaryzować" output
y_test1 = label_binarize(y_test1, classes=[0, 1, 2]) # Uzywam y_test1 ponieważ jest bez one hot encoding
n_classes = y_test1.shape[1]

y_pred = label_binarize(y_pred, classes=[0, 1, 2])

fpr, tpr, roc_auc = dict(), dict(), dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Obliczam micro-average ROC (dla każdej klasy) i pole pod krzywą
fpr["micro"], tpr["micro"], _ = roc_curve(y_test1.ravel(), y_pred.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

plt.figure(figsize = (12,7))
lw = 2
plt.plot(fpr[0], tpr[0], color="darkorange", lw=lw, label="ROC curve - class 0 (AUC = %0.2f)" % roc_auc[0])
plt.plot(fpr[1], tpr[1], color="lightskyblue", lw=lw, label="ROC curve - class 1 (AUC = %0.2f)" % roc_auc[1])
plt.plot(fpr[2], tpr[2], color="limegreen", lw=lw, label="ROC curve - class 2 (AUC = %0.2f)" % roc_auc[2])
plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Krzywa ROC")
plt.legend(loc="lower right")
plt.grid(True, linestyle='-.', color='grey')
plt.show()

"""## Generacja pseudodanych

"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator 

datagen = ImageDataGenerator(
    featurewise_center=True,
    featurewise_std_normalization=True,
    rotation_range=20,
    width_shift_range=0.2, # 0.2 * 100 pikseli = 20 pikseli
    height_shift_range=0.2,
    horizontal_flip=True, # odbicie względem OX
    vertical_flip=True, # odbicie względem OY
    validation_split=0.15, # zbiór walidacyjny 15%
    zoom_range=0.1) # zoom do 10%

# fitowanie danych
datagen.fit(X_train)

# Trenowanie modelu
model_fit_datagen = model.fit(datagen.flow(X_train, y_train,
         batch_size=batch_size, subset='training'),
         validation_data=datagen.flow(X_train, y_train,
         batch_size=batch_size, subset='validation'), epochs=epochs)

"""### Ewaluacja sieci wytrenowanej na pseudodanych"""

# Funkcja służąca do wyrysowania wykresu dokładności (accuracy) i funkcji kosztu w funkcji numeru epoki
def plotTrainingHistory(model):
    plt.figure(figsize = (12,7))

    plt.subplot(1,2,1)
    history = model.history
    plt.plot(history['accuracy'])
    plt.plot(history['val_accuracy'])
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.title('Wykres dokładności w funkcji numeru epoki')
    plt.grid(True, linestyle='-.', color='grey')
    plt.legend(['train', 'validation'], loc='upper left')

    plt.subplot(1,2,2)
    plt.plot(history['loss'])
    plt.plot(history['val_loss'])
    plt.ylabel('loss function')
    plt.xlabel('epoch')
    plt.title('Wykres funkcji kosztu w funkcji numeru epoki')
    plt.grid(True, linestyle='-.', color='grey')
    plt.legend(['train', 'validation'], loc='upper left')
    
plotTrainingHistory(model_fit_datagen)

conf_matrix = printScores(model, X_test, np.argmax(y_test, axis=1))

true0 = conf_matrix[0][0] / np.sum(conf_matrix[0])
true1 = conf_matrix[1][1] / np.sum(conf_matrix[1])
true2 = conf_matrix[2][2] / np.sum(conf_matrix[2])

# Histogram procenta obrazków sklasyfikowanych poprawnie dla każdej z klas
fig = plt.figure(figsize = (8,6))

labels = np.unique(labels, return_counts=False)
plt.bar(labels, [true0, true1, true2], align='center', color=["plum", "thistle","pink"], edgecolor='black', alpha=0.75)
plt.gca().set_xticks(labels)
plt.grid(True, linestyle='-.', color='grey')
plt.ylabel("Procent")
plt.xlabel("klasa")
#plt.ylim(0.8, 1.02)
plt.title("Procent poprawnie sklasyfikowanych obrazków dla każdej z klas")

plt.show()

# Wykres krzywej ROC oraz pole pod krzywą (AUC)
y_pred = np.argmax(model.predict(X_test), axis=1)

# Ponieważ klasyfikacja nie jest binarna, należy "zbinaryzować" output
y_test1 = label_binarize(y_test1, classes=[0, 1, 2]) # Uzywam y_test1 ponieważ jest bez one hot encoding
n_classes = y_test1.shape[1]

y_pred = label_binarize(y_pred, classes=[0, 1, 2])

fpr, tpr, roc_auc = dict(), dict(), dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_pred[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Obliczam micro-average ROC (dla każdej klasy) i pole pod krzywą
fpr["micro"], tpr["micro"], _ = roc_curve(y_test1.ravel(), y_pred.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

plt.figure(figsize = (12,7))
lw = 2
plt.plot(fpr[0], tpr[0], color="darkorange", lw=lw, label="ROC curve - class 0 (AUC = %0.2f)" % roc_auc[0])
plt.plot(fpr[1], tpr[1], color="lightskyblue", lw=lw, label="ROC curve - class 1 (AUC = %0.2f)" % roc_auc[1])
plt.plot(fpr[2], tpr[2], color="limegreen", lw=lw, label="ROC curve - class 2 (AUC = %0.2f)" % roc_auc[2])
plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Krzywa ROC")
plt.legend(loc="lower right")
plt.grid(True, linestyle='-.', color='grey')
plt.show()

"""## Podsumowanie i wnioski
* Sieć neuronowa wytrenowana na wygenerowanych pseudodanych, składających się z oryginalnych obrazków, które obrócono, odbijano w poziomie i w pionie, a także "zoom'owano", okazała się działać gorzej dla niektórych klas, niż sieć uczona na oryginalnych danych. Pseudodane z klasy 0 (zawierające potencjalne błyski gamma) bardzo często mylone były z obrazkami z klasy 2 (zawierającymi artefakty aparaturowe, będące fałszywymi alarmami). Być może obrazki z klasy 0 zawierały cechę, która np. po obróceniu o pewien kąt przypominała cechę charakterystyczną dla klasy 2.

* Sieć wytrenowana na pseudodanych polepszyła jednak w klasyfikowaniu obrazów należących do klasy 1 - podczas klasyfikacji poprawnie sklasyfikowano wszystkie obrazy należące do klasy 1, czyli przedstawiające chmury (fałszywy alarm). Chmury pod wieloma kątami, a także po obracaniu i zoom'owaniu zachowują swoje charakterystyczne cechy. Sieć neuronowa przyswoiła nowe wzorce, które dodatkowo polepszyły rozpoznawanie chmur.  
"""